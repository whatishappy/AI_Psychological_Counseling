/**
 * AIæ¨¡å‹æœåŠ¡æ¨¡å—
 * æä¾›ç»Ÿä¸€çš„æ¥å£æ¥è°ƒç”¨ä¸åŒçš„AIå¤§æ¨¡å‹
 */

import axios from 'axios';

// å®šä¹‰æ”¯æŒçš„AIæ¨¡å‹ç±»å‹
export enum AIModelType {
  MOCK = 'mock',
  QWEN = 'qwen',
  GLM = 'glm'
}

// AIæ¨¡å‹å“åº”æ¥å£
export interface AIModelResponse {
  response: string;
  model: string;
}

// æ¨¡æ‹ŸAIæ¨¡å‹å“åº”
async function mockModel(prompt: string): Promise<AIModelResponse> {
  console.warn('æœªé…ç½®AIæ¨¡å‹å¯†é’¥ï¼Œä½¿ç”¨æ¨¡æ‹Ÿå›å¤');
  return {
    response: `æˆ‘ç†è§£ä½ å…³äº"${prompt}"çš„æƒ³æ³•ã€‚ä½œä¸ºä½ çš„AIå¿ƒç†å’¨è¯¢å¸ˆï¼Œæˆ‘æƒ³è¿›ä¸€æ­¥äº†è§£ä½ çš„æ„Ÿå—ã€‚ä½ èƒ½å‘Šè¯‰æˆ‘æ›´å¤šç›¸å…³çš„ç»†èŠ‚å—ï¼Ÿ`,
    model: 'mock-model'
  };
}

// é€šä¹‰åƒé—®æ¨¡å‹
async function qwenModel(prompt: string): Promise<AIModelResponse> {
  const apiKey = process.env.DASHSCOPE_API_KEY;
  if (!apiKey) {
    console.warn('æœªé…ç½®DASHSCOPE_API_KEYï¼Œä½¿ç”¨æ¨¡æ‹Ÿå›å¤');
    return mockModel(prompt);
  }

  try {
    const response = await axios.post(
      'https://dashscope.aliyuncs.com/api/v1/services/aigc/text-generation/generation',
      {
        model: 'qwen-plus',
        input: {
          prompt: `ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å¿ƒç†åŒ»ç”Ÿï¼Œæ­£åœ¨ä¸ºç”¨æˆ·æä¾›å¿ƒç†å’¨è¯¢æœåŠ¡ã€‚è¯·é’ˆå¯¹ä»¥ä¸‹é—®é¢˜ç»™å‡ºä¸“ä¸šä¸”äººæ€§åŒ–çš„å›å¤ï¼š${prompt}`
        },
        parameters: {
          max_tokens: 1500,
          temperature: 0.8,
          top_p: 0.8
        }
      },
      {
        headers: {
          'Authorization': `Bearer ${apiKey}`,
          'Content-Type': 'application/json'
        }
      }
    );
    
    return {
      response: response.data.output.text,
      model: 'qwen-plus'
    };
  } catch (error) {
    console.error('é€šä¹‰åƒé—®APIè°ƒç”¨é”™è¯¯:', error);
    throw error;
  }
}

// GLMæ¨¡å‹ï¼ˆæ™ºè°±AIï¼‰
async function glmModel(prompt: string): Promise<AIModelResponse> {
  const apiKey = process.env.ZHIPU_AI_API_KEY;
  if (!apiKey) {
    console.warn('æœªé…ç½®ZHIPU_AI_API_KEYï¼Œä½¿ç”¨æ¨¡æ‹Ÿå›å¤');
    return mockModel(prompt);
  }

  try {
    const response = await axios.post(
      'https://open.bigmodel.cn/api/paas/v3/model-api/glm-4/chat/completions',
      {
        model: 'glm-4',
        messages: [
          {
            role: 'system',
            content: 'ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å¿ƒç†åŒ»ç”Ÿï¼Œæ­£åœ¨ä¸ºç”¨æˆ·æä¾›å¿ƒç†å’¨è¯¢æœåŠ¡ã€‚è¯·é’ˆå¯¹ç”¨æˆ·çš„é—®é¢˜ç»™å‡ºä¸“ä¸šä¸”äººæ€§åŒ–çš„å›å¤ã€‚'
          },
          {
            role: 'user',
            content: prompt
          }
        ],
        max_tokens: 1500,
        temperature: 0.8,
        top_p: 0.8
      },
      {
        headers: {
          'Authorization': `Bearer ${apiKey}`,
          'Content-Type': 'application/json'
        }
      }
    );
    
    return {
      response: response.data.choices[0].message.content,
      model: 'glm-4'
    };
  } catch (error) {
    console.error('GLMæ¨¡å‹APIè°ƒç”¨é”™è¯¯:', error);
    throw error;
  }
}

// ç»Ÿä¸€çš„AIæ¨¡å‹è°ƒç”¨æ¥å£
export async function callAIModel(
  prompt: string, 
  modelType: AIModelType = AIModelType.MOCK
): Promise<AIModelResponse> {
  try {
    switch (modelType) {
      case AIModelType.QWEN:
        return await qwenModel(prompt);
      case AIModelType.GLM:
        return await glmModel(prompt);
      case AIModelType.MOCK:
      default:
        return await mockModel(prompt);
    }
  } catch (error) {
    console.error('AIæ¨¡å‹è°ƒç”¨é”™è¯¯:', error);
    // å‡ºé”™æ—¶è¿”å›å®‰å…¨çš„é»˜è®¤å›å¤
    return {
      response: 'æŠ±æ­‰ï¼Œæˆ‘ç°åœ¨æ— æ³•å¾ˆå¥½åœ°å¤„ç†ä½ çš„é—®é¢˜ã€‚è¯·ç¨åå†è¯•ï¼Œæˆ–è€…è”ç³»äººå·¥å¿ƒç†å’¨è¯¢æœåŠ¡ã€‚',
      model: modelType
    };
  }
}
/**
 * AIå¿ƒç†å’¨è¯¢æœåŠ¡ä¸»åº”ç”¨æ–‡ä»¶
 * è¿™æ˜¯ä½¿ç”¨TypeScriptç¼–å†™çš„Expressåº”ç”¨å…¥å£ç‚¹
 */

import express from 'express';
import path from 'path';
import { callAIModel, AIModelType } from './aiService';

// åˆ›å»ºExpressåº”ç”¨å®ä¾‹
const app = express();
// ä»ç¯å¢ƒå˜é‡è·å–ç«¯å£å·ï¼Œé»˜è®¤ä¸º3000
const PORT = process.env.PORT || 3000;

// ä¸­é—´ä»¶é…ç½®
// è§£æJSONè¯·æ±‚ä½“
app.use(express.json());
// æä¾›é™æ€æ–‡ä»¶æœåŠ¡ï¼Œå°†ä¸Šçº§ç›®å½•ä½œä¸ºé™æ€èµ„æºæ ¹ç›®å½•
app.use(express.static(path.join(__dirname, '..')));

// å¥åº·æ£€æŸ¥ç«¯ç‚¹
// ç”¨äºæ£€æŸ¥æœåŠ¡æ˜¯å¦æ­£å¸¸è¿è¡Œ
app.get('/health', (_req, res) => {
  res.json({ 
    ok: true, 
    timestamp: new Date().toISOString(),
    service: 'AI Psychology Platform - Main Application'
  });
});

// APIè·¯ç”±
app.use('/api', (req, res, next) => {
  // è®°å½•APIè¯·æ±‚
  console.log(`API Request: ${req.method} ${req.path}`);
  next();
});

// AIå’¨è¯¢ä¼šè¯ç«¯ç‚¹
interface ConsultationRequest {
  user_query: string;
  consultation_type: string;
}

interface ConsultationResponse {
  consultation_id?: string;
  ai_response: string;
  model_used: string;
  system_prompt?: string;
}

app.post('/api/consultations', async (req, res) => {
  try {
    const { user_query, consultation_type }: ConsultationRequest = req.body;
    
    // éªŒè¯è¯·æ±‚å‚æ•°
    if (!user_query) {
      return res.status(400).json({ 
        error: 'Missing required parameter: user_query' 
      });
    }
    
    // ç¡®å®šè¦ä½¿ç”¨çš„AIæ¨¡å‹ç±»å‹
    let modelType = AIModelType.MOCK;
    const modelEnv = process.env.AI_MODEL_TYPE;
    
    if (modelEnv === 'qwen') {
      modelType = AIModelType.QWEN;
    } else if (modelEnv === 'glm') {
      modelType = AIModelType.GLM;
    }
    
    // è°ƒç”¨AIæ¨¡å‹è·å–å›å¤
    const aiResponse = await callAIModel(user_query, modelType);
    
    const response: ConsultationResponse = {
      consultation_id: 'sess-' + Date.now(),
      ai_response: aiResponse.response,
      model_used: aiResponse.model,
      system_prompt: 'ç³»ç»Ÿæç¤ºè¯å·²è®¾ç½®ï¼ˆä¸æ˜¾ç¤ºç»™ç”¨æˆ·ï¼‰'
    };
    
    console.log('ç³»ç»Ÿæç¤ºè¯å·²è®¾ç½®ï¼ˆä¸æ˜¾ç¤ºç»™ç”¨æˆ·ï¼‰');
    
    // è¿”å›AIå“åº”
    res.json(response);
  } catch (error) {
    console.error('AIå’¨è¯¢å¤„ç†é”™è¯¯:', error);
    res.status(500).json({ 
      error: 'Internal server error while processing consultation' 
    });
  }
});

// æ‰€æœ‰å…¶ä»–GETè¯·æ±‚éƒ½è¿”å›index.html
// æ”¯æŒå‰ç«¯è·¯ç”±ï¼ˆå¦‚Vueã€Reactçš„Browser Historyæ¨¡å¼ï¼‰
app.get('*', (req, res) => {
  // å¦‚æœè¯·æ±‚çš„æ˜¯APIç«¯ç‚¹ä½†æœªæ‰¾åˆ°ï¼Œè¿”å›404
  if (req.path.startsWith('/api/')) {
    res.status(404).json({ 
      error: 'API endpoint not found' 
    });
  } else {
    // å¦åˆ™è¿”å›ä¸»é¡µé¢ï¼Œæ”¯æŒSPAåº”ç”¨
    res.sendFile(path.join(__dirname, '..', 'index.html'));
  }
});

// å¯åŠ¨æœåŠ¡å™¨å¹¶ç›‘å¬æŒ‡å®šç«¯å£
app.listen(PORT, () => {
  console.log(`ğŸš€ Server is running on http://localhost:${PORT}`);
  console.log(`ğŸ“„ Visit http://localhost:${PORT} to access the application`);
  console.log(`ğŸ” Health check: http://localhost:${PORT}/health`);
  
  // æ˜¾ç¤ºå½“å‰ä½¿ç”¨çš„AIæ¨¡å‹
  const modelEnv = process.env.AI_MODEL_TYPE || 'mock';
  console.log(`ğŸ¤– å½“å‰AIæ¨¡å‹: ${modelEnv}`);
  if (modelEnv === 'mock') {
    console.log('ğŸ’¡ æç¤º: è®¾ç½®ç¯å¢ƒå˜é‡ AI_MODEL_TYPE=qwen æˆ– AI_MODEL_TYPE=glm æ¥ä½¿ç”¨çœŸå®AIæ¨¡å‹');
  }
});

// å¯¼å‡ºåº”ç”¨å®ä¾‹ï¼Œä¾¿äºæµ‹è¯•å’Œå¤ç”¨
export default app;